{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1027111b883fd6ae949c4ce3a96a9718",
     "grade": false,
     "grade_id": "cell-7ea049f33e7c8764",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Single-Qubit Gates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5bac332219213275f062743306fcb55f",
     "grade": false,
     "grade_id": "cell-517fe01d3e0bd3be",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X and H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=1)\n",
    "\n",
    "U = np.array([[1, 1], [1, -1]]) / np.sqrt(2)\n",
    "\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def varied_initial_state(state):\n",
    "    \"\"\"Complete the function such that we can apply the operation U to\n",
    "    either |0> or |1> depending on the input argument flag.\n",
    "\n",
    "    Args:\n",
    "        state (int): Either 0 or 1. If 1, prepare the qubit in state |1>,\n",
    "            otherwise, leave it in state 0.\n",
    "\n",
    "    Returns:\n",
    "        np.array[complex]: The state of the qubit after the operations.\n",
    "    \"\"\"\n",
    "    ##################\n",
    "    # YOUR CODE HERE #\n",
    "    if state == 1:\n",
    "        qml.PauliX(0)\n",
    "    qml.QubitUnitary(U,0)\n",
    "    ##################\n",
    "\n",
    "    # KEEP THE QUBIT IN |0> OR CHANGE IT TO |1> DEPENDING ON THE state PARAMETER\n",
    "\n",
    "    # APPLY U TO THE STATE\n",
    "\n",
    "    return qml.state()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=1)\n",
    "\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def apply_hadamard():\n",
    "    ##################\n",
    "    # YOUR CODE HERE #\n",
    "    qml.Hadamard(0)\n",
    "    ##################\n",
    "\n",
    "    # APPLY THE HADAMARD GATE\n",
    "\n",
    "    # RETURN THE STATE\n",
    "    return qml.state()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70710678+0.j 0.70710678+0.j]\n",
      "[ 0.70710678+0.j -0.70710678+0.j]\n"
     ]
    }
   ],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=1)\n",
    "\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def apply_hadamard_to_state(state):\n",
    "    \"\"\"Complete the function such that we can apply the Hadamard to\n",
    "    either |0> or |1> depending on the input argument flag.\n",
    "\n",
    "    Args:\n",
    "        state (int): Either 0 or 1. If 1, prepare the qubit in state |1>,\n",
    "            otherwise, leave it in state 0.\n",
    "\n",
    "    Returns:\n",
    "        np.array[complex]: The state of the qubit after the operations.\n",
    "    \"\"\"\n",
    "    ##################\n",
    "    # YOUR CODE HERE #\n",
    "\n",
    "    if state == 1:\n",
    "        qml.PauliX(0)\n",
    "    qml.Hadamard(0)\n",
    "    ##################\n",
    "\n",
    "    # KEEP THE QUBIT IN |0> OR CHANGE IT TO |1> DEPENDING ON state\n",
    "\n",
    "    # APPLY THE HADAMARD\n",
    "\n",
    "    # RETURN THE STATE\n",
    "\n",
    "    return qml.state()\n",
    "\n",
    "\n",
    "print(apply_hadamard_to_state(0))\n",
    "print(apply_hadamard_to_state(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.+0.j 0.+0.j]\n",
      "[ 0.+0.j -1.+0.j]\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# YOUR CODE HERE #\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=1)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def apply_hxh(state):\n",
    "    if state == 1:\n",
    "        qml.X(0)\n",
    "\n",
    "    qml.Hadamard(0)\n",
    "    qml.X(0)\n",
    "    qml.Hadamard(0)\n",
    "    \n",
    "    return qml.state()\n",
    "\n",
    "##################\n",
    "\n",
    "# CREATE A DEVICE\n",
    "\n",
    "# CREATE A QNODE CALLED apply_hxh THAT APPLIES THE CIRCUIT ABOVE\n",
    "\n",
    "# Print your results\n",
    "print(apply_hxh(0))\n",
    "print(apply_hxh(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's Just a Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.70710678+0.j -0.70710678+0.j]\n"
     ]
    }
   ],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=1)\n",
    "\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def apply_z_to_plus():\n",
    "    \"\"\"Write a circuit that applies PauliZ to the |+> state and returns\n",
    "    the state.\n",
    "\n",
    "    Returns:\n",
    "        np.array[complex]: The state of the qubit after the operations.\n",
    "    \"\"\"\n",
    "\n",
    "    ##################\n",
    "    # YOUR CODE HERE #\n",
    "\n",
    "    qml.Hadamard(0)\n",
    "    qml.Z(0)\n",
    "    ##################\n",
    "\n",
    "    # CREATE THE |+> STATE\n",
    "\n",
    "    # APPLY PAULI Z\n",
    "\n",
    "    # RETURN THE STATE\n",
    "    return qml.state()\n",
    "\n",
    "\n",
    "print(apply_z_to_plus())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=1)\n",
    "\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def fake_z():\n",
    "    \"\"\"Use RZ to produce the same action as Pauli Z on the |+> state.\n",
    "\n",
    "    Returns:\n",
    "        np.array[complex]: The state of the qubit after the operations.\n",
    "    \"\"\"\n",
    "\n",
    "    ##################\n",
    "    # YOUR CODE HERE #\n",
    "\n",
    "    qml.Hadamard(0)\n",
    "    qml.RZ(np.pi, 0)\n",
    "    ##################\n",
    "\n",
    "    # CREATE THE |+> STATE\n",
    "\n",
    "    # APPLY RZ\n",
    "\n",
    "    # RETURN THE STATE\n",
    "    return qml.state()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=1)\n",
    "\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def many_rotations():\n",
    "    \"\"\"Implement the circuit depicted above and return the quantum state.\n",
    "\n",
    "    Returns:\n",
    "        np.array[complex]: The state of the qubit after the operations.\n",
    "    \"\"\"\n",
    "\n",
    "    ##################\n",
    "    # YOUR CODE HERE #\n",
    "\n",
    "    qml.Hadamard(0)\n",
    "    qml.S(0)\n",
    "    qml.adjoint(qml.T)(wires=0)\n",
    "    qml.RZ(0.3, 0)\n",
    "    qml.adjoint(qml.S)(wires=0)\n",
    "\n",
    "    ##################\n",
    "\n",
    "    # IMPLEMENT THE CIRCUIT\n",
    "\n",
    "    # RETURN THE STATE\n",
    "\n",
    "    return qml.state()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From a Different Angle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.123234e-17+0.j 0.000000e+00-1.j]\n",
      "[0.000000e+00-1.j 6.123234e-17+0.j]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\kollah\\AppData\\Local\\Temp\\ipykernel_14108\\1770237105.py:6: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  \"\"\"Apply an RX gate with an angle of \\pi to a particular basis state.\n"
     ]
    }
   ],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=1)\n",
    "\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def apply_rx_pi(state):\n",
    "    \"\"\"Apply an RX gate with an angle of \\pi to a particular basis state.\n",
    "\n",
    "    Args:\n",
    "        state (int): Either 0 or 1. If 1, initialize the qubit to state |1>\n",
    "            before applying other operations.\n",
    "\n",
    "    Returns:\n",
    "        np.array[complex]: The state of the qubit after the operations.\n",
    "    \"\"\"\n",
    "    if state == 1:\n",
    "        qml.PauliX(wires=0)\n",
    "\n",
    "    ##################\n",
    "    # YOUR CODE HERE #\n",
    "\n",
    "    qml.RX(np.pi, 0)\n",
    "    ##################\n",
    "\n",
    "    # APPLY RX(pi) AND RETURN THE STATE\n",
    "\n",
    "    return qml.state()\n",
    "\n",
    "\n",
    "print(apply_rx_pi(0))\n",
    "print(apply_rx_pi(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plotter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m angles \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mpi, \u001b[38;5;241m200\u001b[39m)\n\u001b[0;32m     31\u001b[0m output_states \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([apply_rx(t, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m angles])\n\u001b[1;32m---> 33\u001b[0m plot \u001b[38;5;241m=\u001b[39m \u001b[43mplotter\u001b[49m(angles, output_states)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plotter' is not defined"
     ]
    }
   ],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=1)\n",
    "\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def apply_rx(theta, state):\n",
    "    \"\"\"Apply an RX gate with an angle of theta to a particular basis state.\n",
    "\n",
    "    Args:\n",
    "        theta (float): A rotation angle.\n",
    "        state (int): Either 0 or 1. If 1, initialize the qubit to state |1>\n",
    "            before applying other operations.\n",
    "\n",
    "    Returns:\n",
    "        np.array[complex]: The state of the qubit after the operations.\n",
    "    \"\"\"\n",
    "    if state == 1:\n",
    "        qml.PauliX(wires=0)\n",
    "\n",
    "    ##################\n",
    "    # YOUR CODE HERE #\n",
    "    qml.RX(theta, 0)\n",
    "    ##################\n",
    "\n",
    "    # APPLY RX(theta) AND RETURN THE STATE\n",
    "\n",
    "    return qml.state()\n",
    "\n",
    "\n",
    "# Code for plotting\n",
    "angles = np.linspace(0, 4 * np.pi, 200)\n",
    "output_states = np.array([apply_rx(t, 0) for t in angles])\n",
    "\n",
    "plot = plotter(angles, output_states)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.6.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m angles \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mpi, \u001b[38;5;241m200\u001b[39m)\n\u001b[0;32m     32\u001b[0m output_states \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([apply_ry(t, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m angles])\n\u001b[1;32m---> 34\u001b[0m plot \u001b[38;5;241m=\u001b[39m \u001b[43mplotter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mangles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_states\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=1)\n",
    "\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def apply_ry(theta, state):\n",
    "    \"\"\"Apply an RY gate with an angle of theta to a particular basis state.\n",
    "\n",
    "    Args:\n",
    "        theta (float): A rotation angle.\n",
    "        state (int): Either 0 or 1. If 1, initialize the qubit to state |1>\n",
    "            before applying other operations.\n",
    "\n",
    "    Returns:\n",
    "        np.array[complex]: The state of the qubit after the operations.\n",
    "    \"\"\"\n",
    "    if state == 1:\n",
    "        qml.PauliX(wires=0)\n",
    "\n",
    "    ##################\n",
    "    # YOUR CODE HERE #\n",
    "\n",
    "    qml.RY(theta, 0)\n",
    "    ##################\n",
    "\n",
    "    # APPLY RY(theta) AND RETURN THE STATE\n",
    "\n",
    "    return qml.state()\n",
    "\n",
    "\n",
    "# Code for plotting\n",
    "angles = np.linspace(0, 4 * np.pi, 200)\n",
    "output_states = np.array([apply_ry(t, 0) for t in angles])\n",
    "\n",
    "plot = plotter(angles, output_states)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universal Gate Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=1)\n",
    "\n",
    "##################\n",
    "# YOUR CODE HERE #\n",
    "##################\n",
    "\n",
    "# ADJUST THE VALUES OF PHI, THETA, AND OMEGA\n",
    "phi, theta, omega = np.pi/2, np.pi/2, np.pi/2\n",
    "\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def hadamard_with_rz_rx():\n",
    "    qml.RZ(phi, wires=0)\n",
    "    qml.RX(theta, wires=0)\n",
    "    qml.RZ(omega, wires=0)\n",
    "    return qml.state()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.7.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=1)\n",
    "\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def convert_to_rz_rx():\n",
    "    ##################\n",
    "    # YOUR CODE HERE #\n",
    "    qml.RZ(np.pi/2, wires=0)\n",
    "    qml.RX(np.pi/2, wires=0)\n",
    "    qml.RZ(np.pi/2, wires=0)\n",
    "    \n",
    "    qml.RZ(np.pi/2, 0)\n",
    "    \n",
    "    qml.RZ(-np.pi/4, 0)\n",
    "    \n",
    "    qml.RZ(np.pi/2, 0)\n",
    "    qml.RX(np.pi, 0)\n",
    "    qml.RZ(-np.pi/2, 0)\n",
    "    ##################\n",
    "\n",
    "    # IMPLEMENT THE CIRCUIT IN THE PICTURE USING ONLY RZ AND RX\n",
    "\n",
    "    return qml.state()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.7.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=1)\n",
    "\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def unitary_with_h_and_t():\n",
    "    ##################\n",
    "    # YOUR CODE HERE #\n",
    "    qml.Hadamard(0)\n",
    "    qml.T(0)\n",
    "    qml.Hadamard(0)\n",
    "    qml.T(0)\n",
    "    qml.T(0)\n",
    "    qml.Hadamard(0)\n",
    "    ##################\n",
    "\n",
    "    # APPLY ONLY H AND T TO PRODUCE A CIRCUIT THAT EFFECTS THE GIVEN MATRIX\n",
    "\n",
    "    return qml.state()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=1)\n",
    "\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def prepare_state():\n",
    "    ##################\n",
    "    # YOUR CODE HERE #\n",
    "    qml.Hadamard(0)\n",
    "    qml.S(0)\n",
    "    qml.S(0)\n",
    "    qml.T(0)\n",
    "    ##################\n",
    "\n",
    "    # APPLY OPERATIONS TO PREPARE THE TARGET STATE\n",
    "\n",
    "    return qml.state()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.8.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=1)\n",
    "\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def prepare_state():\n",
    "    ##################\n",
    "    # YOUR CODE HERE #\n",
    "    qml.RX(np.pi/3, 0)\n",
    "    ##################\n",
    "\n",
    "    # APPLY OPERATIONS TO PREPARE THE TARGET STATE\n",
    "\n",
    "    return qml.state()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.52889389-0.14956775j 0.67262317+0.49545818j]\n",
      "\n",
      "0: ──RY(1.98)──RZ(0.91)──GlobalPhase(-0.18)─┤  State\n"
     ]
    }
   ],
   "source": [
    "v = np.array([0.52889389 - 0.14956775j, 0.67262317 + 0.49545818j])\n",
    "\n",
    "##################\n",
    "# YOUR CODE HERE #\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=1)\n",
    "##################\n",
    "\n",
    "# CREATE A DEVICE\n",
    "\n",
    "\n",
    "# CONSTRUCT A QNODE THAT USES qml.MottonenStatePreparation\n",
    "# TO PREPARE A QUBIT IN STATE V, AND RETURN THE STATE\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def prepare_state(state=v):\n",
    "    qml.MottonenStatePreparation(state_vector=state, wires=0)\n",
    "    return qml.state()\n",
    "\n",
    "\n",
    "# This will draw the quantum circuit and allow you to inspect the output gates\n",
    "print(prepare_state(v))\n",
    "print()\n",
    "print(qml.draw(prepare_state, expansion_strategy=\"device\")(v))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.9.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.5]\n",
      "[0.5 0.5]\n"
     ]
    }
   ],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=1)\n",
    "\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def apply_h_and_measure(state):\n",
    "    \"\"\"Complete the function such that we apply the Hadamard gate\n",
    "    and measure in the computational basis.\n",
    "\n",
    "    Args:\n",
    "        state (int): Either 0 or 1. If 1, prepare the qubit in state |1>,\n",
    "            otherwise leave it in state 0.\n",
    "\n",
    "    Returns:\n",
    "        np.array[float]: The measurement outcome probabilities.\n",
    "    \"\"\"\n",
    "    if state == 1:\n",
    "        qml.PauliX(wires=0)\n",
    "\n",
    "    ##################\n",
    "    # YOUR CODE HERE #\n",
    "\n",
    "    qml.Hadamard(0)\n",
    "\n",
    "    ##################\n",
    "\n",
    "    # APPLY HADAMARD AND MEASURE\n",
    "\n",
    "    return qml.probs(wires=0)\n",
    "\n",
    "\n",
    "print(apply_h_and_measure(0))\n",
    "print(apply_h_and_measure(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.9.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# YOUR CODE HERE #\n",
    "##################\n",
    "\n",
    "\n",
    "# WRITE A QUANTUM FUNCTION THAT PREPARES (1/2)|0> + i(sqrt(3)/2)|1>\n",
    "def prepare_psi():\n",
    "    v = np.array([1/2 - 0j, 0 + (np.sqrt(3)/2) * 1j])\n",
    "    qml.MottonenStatePreparation(state_vector=v, wires=0)\n",
    "\n",
    "\n",
    "# WRITE A QUANTUM FUNCTION THAT SENDS BOTH |0> TO |y_+> and |1> TO |y_->\n",
    "def y_basis_rotation():\n",
    "    qml.Hadamard(0)\n",
    "    qml.S(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.9.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9330127 0.0669873]\n"
     ]
    }
   ],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=1)\n",
    "\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def measure_in_y_basis():\n",
    "    ##################\n",
    "    prepare_psi()\n",
    "    qml.adjoint(y_basis_rotation)()\n",
    "    ##################\n",
    "\n",
    "    # PREPARE THE STATE\n",
    "\n",
    "    # PERFORM THE ROTATION BACK TO COMPUTATIONAL BASIS\n",
    "\n",
    "    # RETURN THE MEASUREMENT OUTCOME PROBABILITIES\n",
    "\n",
    "    return qml.probs(wires=0)\n",
    "\n",
    "\n",
    "print(measure_in_y_basis())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Did You Expect?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.10.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.7071067811865471\n"
     ]
    }
   ],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=1)\n",
    "\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit():\n",
    "    ##################\n",
    "    # YOUR CODE HERE #\n",
    "\n",
    "    qml.RX(np.pi/4, 0)\n",
    "    qml.Hadamard(0)\n",
    "    qml.PauliZ(0)\n",
    "    ##################\n",
    "\n",
    "    # IMPLEMENT THE CIRCUIT IN THE PICTURE AND MEASURE PAULI Y\n",
    "\n",
    "    return qml.expval(qml.PauliY(wires=0))\n",
    "\n",
    "\n",
    "print(circuit())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.10.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.72\n",
      "-0.692\n",
      "-0.719\n",
      "-0.70558\n",
      "-0.70593\n",
      "[-0.8, -0.704, -0.706, -0.70664, -0.706932]\n"
     ]
    }
   ],
   "source": [
    "# An array to store your results\n",
    "shot_results = []\n",
    "\n",
    "# Different numbers of shots\n",
    "shot_values = [100, 1000, 10000, 100000, 1000000]\n",
    "\n",
    "for shots in shot_values:\n",
    "    ##################\n",
    "    # YOUR CODE HERE #\n",
    "\n",
    "    dev = qml.device('default.qubit', wires=1, shots=shots)\n",
    "    \n",
    "    @qml.qnode(dev)\n",
    "    def my_circuit():\n",
    "        qml.RX(np.pi/4, 0)\n",
    "        qml.Hadamard(0)\n",
    "        qml.PauliZ(0)\n",
    "    \n",
    "        return qml.expval(qml.PauliY(wires=0))\n",
    "    \n",
    "    shot_results.append(my_circuit())\n",
    "    print(my_circuit())\n",
    "    \n",
    "    \n",
    "    ##################\n",
    "\n",
    "    # CREATE A DEVICE, CREATE A QNODE, AND RUN IT\n",
    "\n",
    "    # STORE RESULT IN SHOT_RESULTS ARRAY\n",
    "    \n",
    "\n",
    "print(qml.math.unwrap(shot_results))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.10.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.70458\n"
     ]
    }
   ],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=1, shots=100000)\n",
    "\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit():\n",
    "    qml.RX(np.pi / 4, wires=0)\n",
    "    qml.Hadamard(wires=0)\n",
    "    qml.PauliZ(wires=0)\n",
    "\n",
    "    ##################\n",
    "    # YOUR CODE HERE #\n",
    "    ##################\n",
    "\n",
    "    # RETURN THE MEASUREMENT SAMPLES OF THE CORRECT OBSERVABLE\n",
    "\n",
    "    return qml.sample(qml.PauliY(wires=0))\n",
    "\n",
    "\n",
    "def compute_expval_from_samples(samples):\n",
    "    \"\"\"Compute the expectation value of an observable given a set of\n",
    "    sample outputs. You can assume that there are two possible outcomes,\n",
    "    1 and -1.\n",
    "\n",
    "    Args:\n",
    "        samples (np.array[float]): 100000 samples representing the results of\n",
    "            running the above circuit.\n",
    "\n",
    "    Returns:\n",
    "        float: the expectation value computed based on samples.\n",
    "    \"\"\"\n",
    "\n",
    "    estimated_expval = 0\n",
    "\n",
    "    ##################\n",
    "    # YOUR CODE HERE #\n",
    "\n",
    "    numPositives = 0\n",
    "    numNegatives = 0\n",
    "\n",
    "    for num in samples:\n",
    "        if num == 1:\n",
    "            numPositives += 1\n",
    "        else:\n",
    "            numNegatives += 1\n",
    "\n",
    "    estimated_expval = (1*numPositives + (-1)*numNegatives)/len(samples)\n",
    "    ##################\n",
    "\n",
    "    # USE THE SAMPLES TO ESTIMATE THE EXPECTATION VALUE\n",
    "\n",
    "    return estimated_expval\n",
    "\n",
    "\n",
    "samples = circuit()\n",
    "print(compute_expval_from_samples(samples))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.10.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.6, requires_grad=True), tensor(-0.6, requires_grad=True), tensor(-0.2, requires_grad=True), tensor(0.2, requires_grad=True), tensor(0.2, requires_grad=True), tensor(0.4, requires_grad=True), tensor(0., requires_grad=True), tensor(-0.2, requires_grad=True), tensor(0., requires_grad=True), tensor(0., requires_grad=True), tensor(-0.4, requires_grad=True), tensor(0.2, requires_grad=True), tensor(0.2, requires_grad=True), tensor(0., requires_grad=True), tensor(0.2, requires_grad=True), tensor(-0.2, requires_grad=True), tensor(0.6, requires_grad=True), tensor(-0.2, requires_grad=True), tensor(0., requires_grad=True), tensor(0.2, requires_grad=True), tensor(-0.2, requires_grad=True), tensor(0., requires_grad=True), tensor(0., requires_grad=True), tensor(-0.2, requires_grad=True), tensor(-0.2, requires_grad=True), tensor(0., requires_grad=True), tensor(0.6, requires_grad=True), tensor(0.4, requires_grad=True), tensor(0., requires_grad=True), tensor(-0.2, requires_grad=True), tensor(-0.4, requires_grad=True), tensor(-0.2, requires_grad=True), tensor(-0.2, requires_grad=True), tensor(0.2, requires_grad=True), tensor(0., requires_grad=True), tensor(-0.6, requires_grad=True), tensor(0., requires_grad=True), tensor(-0.2, requires_grad=True), tensor(0.4, requires_grad=True), tensor(0.8, requires_grad=True), tensor(0.2, requires_grad=True), tensor(0.4, requires_grad=True), tensor(0., requires_grad=True), tensor(0., requires_grad=True), tensor(0., requires_grad=True), tensor(0.4, requires_grad=True), tensor(0., requires_grad=True), tensor(0.4, requires_grad=True), tensor(0.2, requires_grad=True), tensor(0.2, requires_grad=True), tensor(-0.2, requires_grad=True), tensor(0., requires_grad=True), tensor(0.6, requires_grad=True), tensor(-0.2, requires_grad=True), tensor(0., requires_grad=True), tensor(-0.4, requires_grad=True), tensor(-0.2, requires_grad=True), tensor(-0.2, requires_grad=True), tensor(0., requires_grad=True), tensor(-0.6, requires_grad=True), tensor(-0.2, requires_grad=True), tensor(0., requires_grad=True), tensor(0.4, requires_grad=True), tensor(-0.4, requires_grad=True), tensor(0.2, requires_grad=True), tensor(0.2, requires_grad=True), tensor(0.2, requires_grad=True), tensor(-0.6, requires_grad=True), tensor(0.8, requires_grad=True), tensor(0., requires_grad=True), tensor(0., requires_grad=True), tensor(-0.4, requires_grad=True), tensor(0., requires_grad=True), tensor(-0.2, requires_grad=True), tensor(-0.2, requires_grad=True), tensor(-0.4, requires_grad=True), tensor(-0.2, requires_grad=True), tensor(0., requires_grad=True), tensor(0., requires_grad=True), tensor(0.2, requires_grad=True), tensor(-0.4, requires_grad=True), tensor(-0.2, requires_grad=True), tensor(-0.4, requires_grad=True), tensor(-0.2, requires_grad=True), tensor(0.6, requires_grad=True), tensor(-0.2, requires_grad=True), tensor(0.4, requires_grad=True), tensor(0., requires_grad=True), tensor(-0.2, requires_grad=True), tensor(-0.2, requires_grad=True), tensor(0., requires_grad=True), tensor(0., requires_grad=True), tensor(-0.6, requires_grad=True), tensor(-0.4, requires_grad=True), tensor(0.2, requires_grad=True), tensor(0.2, requires_grad=True), tensor(-0.8, requires_grad=True), tensor(-0.2, requires_grad=True), tensor(0.4, requires_grad=True), tensor(0.4, requires_grad=True)]\n",
      "[tensor(0.1, requires_grad=True), tensor(-0.1, requires_grad=True), tensor(0.2, requires_grad=True), tensor(-0.3, requires_grad=True), tensor(0.1, requires_grad=True), tensor(0.3, requires_grad=True), tensor(-0.1, requires_grad=True), tensor(0., requires_grad=True), tensor(0., requires_grad=True), tensor(0.1, requires_grad=True), tensor(0.1, requires_grad=True), tensor(-0.1, requires_grad=True), tensor(0., requires_grad=True), tensor(-0.1, requires_grad=True), tensor(-0.1, requires_grad=True), tensor(0., requires_grad=True), tensor(0.1, requires_grad=True), tensor(0.1, requires_grad=True), tensor(0.3, requires_grad=True), tensor(0.2, requires_grad=True), tensor(0.2, requires_grad=True), tensor(0., requires_grad=True), tensor(0.1, requires_grad=True), tensor(-0.1, requires_grad=True), tensor(0.4, requires_grad=True), tensor(0., requires_grad=True), tensor(-0.5, requires_grad=True), tensor(-0.1, requires_grad=True), tensor(0., requires_grad=True), tensor(-0.3, requires_grad=True), tensor(-0.1, requires_grad=True), tensor(0.3, requires_grad=True), tensor(0.2, requires_grad=True), tensor(0., requires_grad=True), tensor(0.2, requires_grad=True), tensor(0.1, requires_grad=True), tensor(0., requires_grad=True), tensor(0., requires_grad=True), tensor(0.1, requires_grad=True), tensor(0.2, requires_grad=True), tensor(0.1, requires_grad=True), tensor(-0.2, requires_grad=True), tensor(-0.2, requires_grad=True), tensor(0., requires_grad=True), tensor(0.1, requires_grad=True), tensor(-0.1, requires_grad=True), tensor(-0.4, requires_grad=True), tensor(0.1, requires_grad=True), tensor(0.2, requires_grad=True), tensor(0.1, requires_grad=True), tensor(0., requires_grad=True), tensor(-0.1, requires_grad=True), tensor(0.4, requires_grad=True), tensor(0.3, requires_grad=True), tensor(0.2, requires_grad=True), tensor(0.1, requires_grad=True), tensor(0., requires_grad=True), tensor(0.1, requires_grad=True), tensor(0.3, requires_grad=True), tensor(0., requires_grad=True), tensor(0.3, requires_grad=True), tensor(0., requires_grad=True), tensor(0.2, requires_grad=True), tensor(0.2, requires_grad=True), tensor(0.1, requires_grad=True), tensor(-0.1, requires_grad=True), tensor(-0.5, requires_grad=True), tensor(-0.1, requires_grad=True), tensor(-0.3, requires_grad=True), tensor(0.1, requires_grad=True), tensor(-0.1, requires_grad=True), tensor(-0.2, requires_grad=True), tensor(-0.3, requires_grad=True), tensor(0., requires_grad=True), tensor(0.4, requires_grad=True), tensor(0., requires_grad=True), tensor(0., requires_grad=True), tensor(0., requires_grad=True), tensor(0.2, requires_grad=True), tensor(0.1, requires_grad=True), tensor(-0.1, requires_grad=True), tensor(0.2, requires_grad=True), tensor(0., requires_grad=True), tensor(0., requires_grad=True), tensor(0., requires_grad=True), tensor(0.4, requires_grad=True), tensor(0.1, requires_grad=True), tensor(0.3, requires_grad=True), tensor(0.4, requires_grad=True), tensor(-0.1, requires_grad=True), tensor(0.2, requires_grad=True), tensor(0.4, requires_grad=True), tensor(0.4, requires_grad=True), tensor(0.2, requires_grad=True), tensor(-0.1, requires_grad=True), tensor(-0.6, requires_grad=True), tensor(0.2, requires_grad=True), tensor(0.1, requires_grad=True), tensor(0.1, requires_grad=True), tensor(0.3, requires_grad=True)]\n",
      "[tensor(0., requires_grad=True), tensor(-0.2, requires_grad=True), tensor(0.15, requires_grad=True), tensor(0.05, requires_grad=True), tensor(0.15, requires_grad=True), tensor(0., requires_grad=True), tensor(-0.1, requires_grad=True), tensor(0.05, requires_grad=True), tensor(0.05, requires_grad=True), tensor(0.1, requires_grad=True), tensor(0.2, requires_grad=True), tensor(-0.3, requires_grad=True), tensor(0.25, requires_grad=True), tensor(0.1, requires_grad=True), tensor(-0.1, requires_grad=True), tensor(0.15, requires_grad=True), tensor(0.1, requires_grad=True), tensor(0.05, requires_grad=True), tensor(-0.05, requires_grad=True), tensor(-0.15, requires_grad=True), tensor(0.15, requires_grad=True), tensor(-0.1, requires_grad=True), tensor(-0.05, requires_grad=True), tensor(-0.2, requires_grad=True), tensor(0.05, requires_grad=True), tensor(-0.1, requires_grad=True), tensor(0.3, requires_grad=True), tensor(0., requires_grad=True), tensor(-0.15, requires_grad=True), tensor(-0.1, requires_grad=True), tensor(0., requires_grad=True), tensor(-0.05, requires_grad=True), tensor(-0.4, requires_grad=True), tensor(0.1, requires_grad=True), tensor(-0.15, requires_grad=True), tensor(0.05, requires_grad=True), tensor(0.2, requires_grad=True), tensor(0.05, requires_grad=True), tensor(-0.05, requires_grad=True), tensor(0.05, requires_grad=True), tensor(0.3, requires_grad=True), tensor(-0.25, requires_grad=True), tensor(-0.05, requires_grad=True), tensor(0.05, requires_grad=True), tensor(0.1, requires_grad=True), tensor(0., requires_grad=True), tensor(-0.05, requires_grad=True), tensor(-0.1, requires_grad=True), tensor(-0.25, requires_grad=True), tensor(0.05, requires_grad=True), tensor(-0.1, requires_grad=True), tensor(0.25, requires_grad=True), tensor(0.15, requires_grad=True), tensor(0.2, requires_grad=True), tensor(-0.25, requires_grad=True), tensor(0.1, requires_grad=True), tensor(0., requires_grad=True), tensor(0.05, requires_grad=True), tensor(0.05, requires_grad=True), tensor(0., requires_grad=True), tensor(0.05, requires_grad=True), tensor(0.05, requires_grad=True), tensor(0., requires_grad=True), tensor(0.05, requires_grad=True), tensor(-0.15, requires_grad=True), tensor(0.25, requires_grad=True), tensor(-0.25, requires_grad=True), tensor(0.15, requires_grad=True), tensor(-0.05, requires_grad=True), tensor(-0.15, requires_grad=True), tensor(-0.2, requires_grad=True), tensor(-0.15, requires_grad=True), tensor(0.15, requires_grad=True), tensor(0.1, requires_grad=True), tensor(-0.05, requires_grad=True), tensor(0.05, requires_grad=True), tensor(0.1, requires_grad=True), tensor(0.1, requires_grad=True), tensor(0.1, requires_grad=True), tensor(-0.25, requires_grad=True), tensor(-0.1, requires_grad=True), tensor(-0.1, requires_grad=True), tensor(0.15, requires_grad=True), tensor(-0.05, requires_grad=True), tensor(0.1, requires_grad=True), tensor(0.1, requires_grad=True), tensor(0., requires_grad=True), tensor(0.05, requires_grad=True), tensor(-0.1, requires_grad=True), tensor(0.2, requires_grad=True), tensor(-0.2, requires_grad=True), tensor(0.15, requires_grad=True), tensor(-0.25, requires_grad=True), tensor(0., requires_grad=True), tensor(0.05, requires_grad=True), tensor(-0.45, requires_grad=True), tensor(-0.25, requires_grad=True), tensor(-0.05, requires_grad=True), tensor(0.25, requires_grad=True), tensor(-0.1, requires_grad=True)]\n",
      "[tensor(0.02, requires_grad=True), tensor(-0.2, requires_grad=True), tensor(-0.04, requires_grad=True), tensor(0.2, requires_grad=True), tensor(0.18, requires_grad=True), tensor(0.16, requires_grad=True), tensor(-0.14, requires_grad=True), tensor(0.04, requires_grad=True), tensor(0.12, requires_grad=True), tensor(-0.04, requires_grad=True), tensor(0., requires_grad=True), tensor(-0.06, requires_grad=True), tensor(0.18, requires_grad=True), tensor(-0.06, requires_grad=True), tensor(-0.06, requires_grad=True), tensor(0.04, requires_grad=True), tensor(-0.06, requires_grad=True), tensor(-0.02, requires_grad=True), tensor(-0.02, requires_grad=True), tensor(0.04, requires_grad=True), tensor(0.1, requires_grad=True), tensor(0., requires_grad=True), tensor(0.04, requires_grad=True), tensor(0.02, requires_grad=True), tensor(0.06, requires_grad=True), tensor(0., requires_grad=True), tensor(0., requires_grad=True), tensor(-0.14, requires_grad=True), tensor(0.06, requires_grad=True), tensor(0., requires_grad=True), tensor(0.16, requires_grad=True), tensor(0., requires_grad=True), tensor(0.08, requires_grad=True), tensor(0.02, requires_grad=True), tensor(0., requires_grad=True), tensor(0.14, requires_grad=True), tensor(-0.04, requires_grad=True), tensor(-0.02, requires_grad=True), tensor(-0.14, requires_grad=True), tensor(-0.12, requires_grad=True), tensor(-0.04, requires_grad=True), tensor(0.1, requires_grad=True), tensor(0.02, requires_grad=True), tensor(0.08, requires_grad=True), tensor(-0.02, requires_grad=True), tensor(0.1, requires_grad=True), tensor(0.04, requires_grad=True), tensor(-0.16, requires_grad=True), tensor(-0.22, requires_grad=True), tensor(-0.1, requires_grad=True), tensor(0.08, requires_grad=True), tensor(0.08, requires_grad=True), tensor(0., requires_grad=True), tensor(-0.12, requires_grad=True), tensor(0.04, requires_grad=True), tensor(0., requires_grad=True), tensor(0.06, requires_grad=True), tensor(0., requires_grad=True), tensor(0.02, requires_grad=True), tensor(-0.06, requires_grad=True), tensor(-0.02, requires_grad=True), tensor(-0.12, requires_grad=True), tensor(0.14, requires_grad=True), tensor(-0.02, requires_grad=True), tensor(0.04, requires_grad=True), tensor(-0.08, requires_grad=True), tensor(-0.06, requires_grad=True), tensor(-0.1, requires_grad=True), tensor(0.02, requires_grad=True), tensor(0.08, requires_grad=True), tensor(0.08, requires_grad=True), tensor(-0.08, requires_grad=True), tensor(0.12, requires_grad=True), tensor(0.04, requires_grad=True), tensor(0., requires_grad=True), tensor(0.06, requires_grad=True), tensor(-0.1, requires_grad=True), tensor(-0.06, requires_grad=True), tensor(-0.16, requires_grad=True), tensor(0.06, requires_grad=True), tensor(0.12, requires_grad=True), tensor(-0.04, requires_grad=True), tensor(0.04, requires_grad=True), tensor(-0.06, requires_grad=True), tensor(0.02, requires_grad=True), tensor(-0.1, requires_grad=True), tensor(0.08, requires_grad=True), tensor(0.16, requires_grad=True), tensor(0., requires_grad=True), tensor(-0.08, requires_grad=True), tensor(-0.12, requires_grad=True), tensor(-0.02, requires_grad=True), tensor(0.16, requires_grad=True), tensor(0., requires_grad=True), tensor(-0.1, requires_grad=True), tensor(0.18, requires_grad=True), tensor(-0.18, requires_grad=True), tensor(0.04, requires_grad=True), tensor(0.04, requires_grad=True), tensor(-0.16, requires_grad=True)]\n",
      "[tensor(0.11, requires_grad=True), tensor(0.01, requires_grad=True), tensor(0., requires_grad=True), tensor(-0.03, requires_grad=True), tensor(0.1, requires_grad=True), tensor(0., requires_grad=True), tensor(0., requires_grad=True), tensor(0., requires_grad=True), tensor(0.13, requires_grad=True), tensor(-0.03, requires_grad=True), tensor(-0.16, requires_grad=True), tensor(-0.01, requires_grad=True), tensor(-0.01, requires_grad=True), tensor(0.06, requires_grad=True), tensor(0.04, requires_grad=True), tensor(-0.03, requires_grad=True), tensor(-0.13, requires_grad=True), tensor(-0.1, requires_grad=True), tensor(-0.07, requires_grad=True), tensor(-0.11, requires_grad=True), tensor(-0.06, requires_grad=True), tensor(0.08, requires_grad=True), tensor(0.04, requires_grad=True), tensor(0.03, requires_grad=True), tensor(-0.01, requires_grad=True), tensor(0.17, requires_grad=True), tensor(0.03, requires_grad=True), tensor(-0.03, requires_grad=True), tensor(-0.02, requires_grad=True), tensor(0.05, requires_grad=True), tensor(0.09, requires_grad=True), tensor(-0.05, requires_grad=True), tensor(-0.08, requires_grad=True), tensor(-0.01, requires_grad=True), tensor(-0.13, requires_grad=True), tensor(-0.07, requires_grad=True), tensor(-0.21, requires_grad=True), tensor(-0.08, requires_grad=True), tensor(0.03, requires_grad=True), tensor(-0.07, requires_grad=True), tensor(0.11, requires_grad=True), tensor(0.11, requires_grad=True), tensor(0.08, requires_grad=True), tensor(-0.04, requires_grad=True), tensor(0., requires_grad=True), tensor(0.06, requires_grad=True), tensor(0.08, requires_grad=True), tensor(-0.08, requires_grad=True), tensor(-0.05, requires_grad=True), tensor(0.05, requires_grad=True), tensor(-0.04, requires_grad=True), tensor(0.02, requires_grad=True), tensor(0.08, requires_grad=True), tensor(-0.05, requires_grad=True), tensor(-0.16, requires_grad=True), tensor(0.03, requires_grad=True), tensor(-0.01, requires_grad=True), tensor(0.01, requires_grad=True), tensor(0.03, requires_grad=True), tensor(-0.06, requires_grad=True), tensor(0.19, requires_grad=True), tensor(0.09, requires_grad=True), tensor(-0.03, requires_grad=True), tensor(-0.04, requires_grad=True), tensor(0.12, requires_grad=True), tensor(0.05, requires_grad=True), tensor(0.05, requires_grad=True), tensor(0.13, requires_grad=True), tensor(0.01, requires_grad=True), tensor(0.1, requires_grad=True), tensor(-0.06, requires_grad=True), tensor(0.12, requires_grad=True), tensor(0.06, requires_grad=True), tensor(0.05, requires_grad=True), tensor(-0.07, requires_grad=True), tensor(0.03, requires_grad=True), tensor(0., requires_grad=True), tensor(0.08, requires_grad=True), tensor(-0.03, requires_grad=True), tensor(0.11, requires_grad=True), tensor(0., requires_grad=True), tensor(0.06, requires_grad=True), tensor(-0.03, requires_grad=True), tensor(0.02, requires_grad=True), tensor(-0.06, requires_grad=True), tensor(0.15, requires_grad=True), tensor(0.1, requires_grad=True), tensor(-0.12, requires_grad=True), tensor(-0.01, requires_grad=True), tensor(-0.04, requires_grad=True), tensor(-0.04, requires_grad=True), tensor(-0.09, requires_grad=True), tensor(0.09, requires_grad=True), tensor(0., requires_grad=True), tensor(-0.04, requires_grad=True), tensor(0.01, requires_grad=True), tensor(-0.01, requires_grad=True), tensor(0.15, requires_grad=True), tensor(-0.02, requires_grad=True), tensor(-0.09, requires_grad=True)]\n",
      "[tensor(0.02, requires_grad=True), tensor(-0.025, requires_grad=True), tensor(-0.045, requires_grad=True), tensor(-0.035, requires_grad=True), tensor(-0.01, requires_grad=True), tensor(0.04, requires_grad=True), tensor(-0.04, requires_grad=True), tensor(-0.075, requires_grad=True), tensor(-0.01, requires_grad=True), tensor(0.025, requires_grad=True), tensor(-0.105, requires_grad=True), tensor(-0.02, requires_grad=True), tensor(-0.035, requires_grad=True), tensor(0.025, requires_grad=True), tensor(-0.085, requires_grad=True), tensor(0.01, requires_grad=True), tensor(0.075, requires_grad=True), tensor(0., requires_grad=True), tensor(-0.025, requires_grad=True), tensor(0.02, requires_grad=True), tensor(0.05, requires_grad=True), tensor(-0.075, requires_grad=True), tensor(-0.015, requires_grad=True), tensor(0.045, requires_grad=True), tensor(-0.055, requires_grad=True), tensor(-0.07, requires_grad=True), tensor(0.03, requires_grad=True), tensor(-0.035, requires_grad=True), tensor(0., requires_grad=True), tensor(0.01, requires_grad=True), tensor(-0.035, requires_grad=True), tensor(-0.035, requires_grad=True), tensor(-0.04, requires_grad=True), tensor(0., requires_grad=True), tensor(0.065, requires_grad=True), tensor(0.05, requires_grad=True), tensor(0.03, requires_grad=True), tensor(0.04, requires_grad=True), tensor(-0.025, requires_grad=True), tensor(0.01, requires_grad=True), tensor(-0.045, requires_grad=True), tensor(-0.04, requires_grad=True), tensor(-0.055, requires_grad=True), tensor(0.055, requires_grad=True), tensor(0.015, requires_grad=True), tensor(0.035, requires_grad=True), tensor(0.01, requires_grad=True), tensor(-0.085, requires_grad=True), tensor(0.1, requires_grad=True), tensor(-0.085, requires_grad=True), tensor(-0.09, requires_grad=True), tensor(-0.065, requires_grad=True), tensor(-0.06, requires_grad=True), tensor(-0.015, requires_grad=True), tensor(0.04, requires_grad=True), tensor(0.095, requires_grad=True), tensor(-0.01, requires_grad=True), tensor(0.11, requires_grad=True), tensor(-0.02, requires_grad=True), tensor(0.03, requires_grad=True), tensor(-0.08, requires_grad=True), tensor(0.035, requires_grad=True), tensor(-0.055, requires_grad=True), tensor(-0.015, requires_grad=True), tensor(0.06, requires_grad=True), tensor(-0.02, requires_grad=True), tensor(-0.02, requires_grad=True), tensor(0.025, requires_grad=True), tensor(0.145, requires_grad=True), tensor(0.01, requires_grad=True), tensor(0.105, requires_grad=True), tensor(-0.095, requires_grad=True), tensor(0.175, requires_grad=True), tensor(-0.04, requires_grad=True), tensor(-0.01, requires_grad=True), tensor(0.105, requires_grad=True), tensor(-0.03, requires_grad=True), tensor(-0.025, requires_grad=True), tensor(-0.025, requires_grad=True), tensor(-0.025, requires_grad=True), tensor(0.025, requires_grad=True), tensor(0.015, requires_grad=True), tensor(-0.03, requires_grad=True), tensor(-0.075, requires_grad=True), tensor(0.03, requires_grad=True), tensor(-0.03, requires_grad=True), tensor(0.005, requires_grad=True), tensor(0.06, requires_grad=True), tensor(0.03, requires_grad=True), tensor(-0.05, requires_grad=True), tensor(0.03, requires_grad=True), tensor(-0.05, requires_grad=True), tensor(-0.06, requires_grad=True), tensor(0.01, requires_grad=True), tensor(0.04, requires_grad=True), tensor(-0.03, requires_grad=True), tensor(0.045, requires_grad=True), tensor(-0.05, requires_grad=True), tensor(-0.04, requires_grad=True), tensor(0.01, requires_grad=True)]\n",
      "[tensor(-0.002, requires_grad=True), tensor(-0.032, requires_grad=True), tensor(-0.01, requires_grad=True), tensor(0.012, requires_grad=True), tensor(0.042, requires_grad=True), tensor(-0.008, requires_grad=True), tensor(0.008, requires_grad=True), tensor(-0.026, requires_grad=True), tensor(0.006, requires_grad=True), tensor(0.01, requires_grad=True), tensor(0.024, requires_grad=True), tensor(-0.002, requires_grad=True), tensor(0.002, requires_grad=True), tensor(-0.004, requires_grad=True), tensor(0.004, requires_grad=True), tensor(-0.016, requires_grad=True), tensor(0.02, requires_grad=True), tensor(0.014, requires_grad=True), tensor(0.03, requires_grad=True), tensor(0.016, requires_grad=True), tensor(-0.016, requires_grad=True), tensor(-0.02, requires_grad=True), tensor(0.022, requires_grad=True), tensor(0.014, requires_grad=True), tensor(0.052, requires_grad=True), tensor(-0.058, requires_grad=True), tensor(-0.018, requires_grad=True), tensor(-0.004, requires_grad=True), tensor(-0.064, requires_grad=True), tensor(0.042, requires_grad=True), tensor(0.006, requires_grad=True), tensor(-0.034, requires_grad=True), tensor(0.03, requires_grad=True), tensor(-0.01, requires_grad=True), tensor(0.018, requires_grad=True), tensor(-0.024, requires_grad=True), tensor(0.04, requires_grad=True), tensor(0.022, requires_grad=True), tensor(0.004, requires_grad=True), tensor(0.024, requires_grad=True), tensor(-0.03, requires_grad=True), tensor(0.026, requires_grad=True), tensor(0.01, requires_grad=True), tensor(0.004, requires_grad=True), tensor(0.036, requires_grad=True), tensor(0.016, requires_grad=True), tensor(-0.046, requires_grad=True), tensor(0.048, requires_grad=True), tensor(0.018, requires_grad=True), tensor(0.048, requires_grad=True), tensor(0.012, requires_grad=True), tensor(0.066, requires_grad=True), tensor(0.05, requires_grad=True), tensor(-0.006, requires_grad=True), tensor(0.03, requires_grad=True), tensor(0.026, requires_grad=True), tensor(0.048, requires_grad=True), tensor(-0.032, requires_grad=True), tensor(-0.014, requires_grad=True), tensor(0.004, requires_grad=True), tensor(-0.04, requires_grad=True), tensor(-0.006, requires_grad=True), tensor(0.058, requires_grad=True), tensor(0.008, requires_grad=True), tensor(0.012, requires_grad=True), tensor(0.026, requires_grad=True), tensor(0.018, requires_grad=True), tensor(0.05, requires_grad=True), tensor(-0.05, requires_grad=True), tensor(-0.008, requires_grad=True), tensor(-0.044, requires_grad=True), tensor(-0.002, requires_grad=True), tensor(-0.006, requires_grad=True), tensor(-0.052, requires_grad=True), tensor(-0.01, requires_grad=True), tensor(0.034, requires_grad=True), tensor(0.01, requires_grad=True), tensor(-0.004, requires_grad=True), tensor(-0.016, requires_grad=True), tensor(0.002, requires_grad=True), tensor(-0.024, requires_grad=True), tensor(-0.044, requires_grad=True), tensor(0.008, requires_grad=True), tensor(-0.006, requires_grad=True), tensor(-0.012, requires_grad=True), tensor(-0.034, requires_grad=True), tensor(-0.022, requires_grad=True), tensor(-0.086, requires_grad=True), tensor(-0.002, requires_grad=True), tensor(0.036, requires_grad=True), tensor(0.01, requires_grad=True), tensor(0.004, requires_grad=True), tensor(-0.048, requires_grad=True), tensor(0., requires_grad=True), tensor(-0.02, requires_grad=True), tensor(-0.038, requires_grad=True), tensor(-0.002, requires_grad=True), tensor(0.01, requires_grad=True), tensor(-0.024, requires_grad=True), tensor(-0.022, requires_grad=True)]\n",
      "[tensor(0.018, requires_grad=True), tensor(0.005, requires_grad=True), tensor(-0.017, requires_grad=True), tensor(0.009, requires_grad=True), tensor(-0.022, requires_grad=True), tensor(-0.033, requires_grad=True), tensor(0.005, requires_grad=True), tensor(0.009, requires_grad=True), tensor(0.01, requires_grad=True), tensor(0.019, requires_grad=True), tensor(0.003, requires_grad=True), tensor(0.008, requires_grad=True), tensor(0.008, requires_grad=True), tensor(-0.005, requires_grad=True), tensor(0.036, requires_grad=True), tensor(0.014, requires_grad=True), tensor(-0.013, requires_grad=True), tensor(0.008, requires_grad=True), tensor(-0.014, requires_grad=True), tensor(-0.036, requires_grad=True), tensor(-0.017, requires_grad=True), tensor(-0.008, requires_grad=True), tensor(-0.003, requires_grad=True), tensor(-0.056, requires_grad=True), tensor(0.007, requires_grad=True), tensor(0.01, requires_grad=True), tensor(0.046, requires_grad=True), tensor(0.005, requires_grad=True), tensor(0.034, requires_grad=True), tensor(-0.034, requires_grad=True), tensor(-0.005, requires_grad=True), tensor(0.005, requires_grad=True), tensor(-0.012, requires_grad=True), tensor(-0.005, requires_grad=True), tensor(0.05, requires_grad=True), tensor(0.019, requires_grad=True), tensor(-0.009, requires_grad=True), tensor(-0.004, requires_grad=True), tensor(0.02, requires_grad=True), tensor(0., requires_grad=True), tensor(-0.022, requires_grad=True), tensor(0.011, requires_grad=True), tensor(-0.021, requires_grad=True), tensor(0.003, requires_grad=True), tensor(-0.024, requires_grad=True), tensor(-0.043, requires_grad=True), tensor(0.033, requires_grad=True), tensor(-0.024, requires_grad=True), tensor(0.006, requires_grad=True), tensor(0.029, requires_grad=True), tensor(0.027, requires_grad=True), tensor(0., requires_grad=True), tensor(0.029, requires_grad=True), tensor(-0.045, requires_grad=True), tensor(-0.017, requires_grad=True), tensor(-0.031, requires_grad=True), tensor(0.019, requires_grad=True), tensor(0.021, requires_grad=True), tensor(0.017, requires_grad=True), tensor(-0.038, requires_grad=True), tensor(0.011, requires_grad=True), tensor(-0.033, requires_grad=True), tensor(-0.021, requires_grad=True), tensor(0.031, requires_grad=True), tensor(0.015, requires_grad=True), tensor(0.015, requires_grad=True), tensor(-0.012, requires_grad=True), tensor(-0.063, requires_grad=True), tensor(-0.001, requires_grad=True), tensor(-0.005, requires_grad=True), tensor(-0.027, requires_grad=True), tensor(0.011, requires_grad=True), tensor(-0.02, requires_grad=True), tensor(0.016, requires_grad=True), tensor(-0.005, requires_grad=True), tensor(-0.007, requires_grad=True), tensor(0.023, requires_grad=True), tensor(-0.033, requires_grad=True), tensor(0.03, requires_grad=True), tensor(0.005, requires_grad=True), tensor(0.01, requires_grad=True), tensor(0.025, requires_grad=True), tensor(-0.009, requires_grad=True), tensor(0.029, requires_grad=True), tensor(-0.023, requires_grad=True), tensor(0.023, requires_grad=True), tensor(0.001, requires_grad=True), tensor(0.044, requires_grad=True), tensor(-0.017, requires_grad=True), tensor(0.002, requires_grad=True), tensor(-0.007, requires_grad=True), tensor(-0.048, requires_grad=True), tensor(0., requires_grad=True), tensor(-0.003, requires_grad=True), tensor(0.023, requires_grad=True), tensor(0.013, requires_grad=True), tensor(-0.01, requires_grad=True), tensor(-0.021, requires_grad=True), tensor(0.004, requires_grad=True), tensor(-0.022, requires_grad=True)]\n",
      "[tensor(0.0115, requires_grad=True), tensor(0.0085, requires_grad=True), tensor(0.022, requires_grad=True), tensor(-0.01, requires_grad=True), tensor(-0.019, requires_grad=True), tensor(-0.0035, requires_grad=True), tensor(-0.0005, requires_grad=True), tensor(0.003, requires_grad=True), tensor(-0.007, requires_grad=True), tensor(0.0365, requires_grad=True), tensor(0.002, requires_grad=True), tensor(-0.0025, requires_grad=True), tensor(0.001, requires_grad=True), tensor(-0.006, requires_grad=True), tensor(0.01, requires_grad=True), tensor(0.0055, requires_grad=True), tensor(0.03, requires_grad=True), tensor(-0.021, requires_grad=True), tensor(-0.0035, requires_grad=True), tensor(0.018, requires_grad=True), tensor(-0.039, requires_grad=True), tensor(0.003, requires_grad=True), tensor(0.003, requires_grad=True), tensor(0.024, requires_grad=True), tensor(0.008, requires_grad=True), tensor(-0.018, requires_grad=True), tensor(-0.0095, requires_grad=True), tensor(-0.015, requires_grad=True), tensor(-0.012, requires_grad=True), tensor(0.03, requires_grad=True), tensor(-0.0065, requires_grad=True), tensor(-0.0055, requires_grad=True), tensor(0.0055, requires_grad=True), tensor(0.017, requires_grad=True), tensor(-0.0035, requires_grad=True), tensor(-0.0125, requires_grad=True), tensor(0.0185, requires_grad=True), tensor(-0.011, requires_grad=True), tensor(0.013, requires_grad=True), tensor(-0.0125, requires_grad=True), tensor(0.0025, requires_grad=True), tensor(0.0255, requires_grad=True), tensor(0.0265, requires_grad=True), tensor(-0.024, requires_grad=True), tensor(0.0225, requires_grad=True), tensor(0.0305, requires_grad=True), tensor(0.005, requires_grad=True), tensor(-0.024, requires_grad=True), tensor(-0.0225, requires_grad=True), tensor(0.0105, requires_grad=True), tensor(0.007, requires_grad=True), tensor(0.027, requires_grad=True), tensor(0.003, requires_grad=True), tensor(-0.007, requires_grad=True), tensor(0.003, requires_grad=True), tensor(0.004, requires_grad=True), tensor(-0.021, requires_grad=True), tensor(0.003, requires_grad=True), tensor(0.0125, requires_grad=True), tensor(0.0075, requires_grad=True), tensor(0.019, requires_grad=True), tensor(-0.007, requires_grad=True), tensor(-0.0045, requires_grad=True), tensor(0.0335, requires_grad=True), tensor(0.006, requires_grad=True), tensor(-0.015, requires_grad=True), tensor(-0.005, requires_grad=True), tensor(0.014, requires_grad=True), tensor(0.026, requires_grad=True), tensor(-0.0105, requires_grad=True), tensor(-0.027, requires_grad=True), tensor(-0.0175, requires_grad=True), tensor(-0.01, requires_grad=True), tensor(-0.0065, requires_grad=True), tensor(-0.0075, requires_grad=True), tensor(-0.0045, requires_grad=True), tensor(0.0055, requires_grad=True), tensor(0.0115, requires_grad=True), tensor(-0.012, requires_grad=True), tensor(0.008, requires_grad=True), tensor(0.003, requires_grad=True), tensor(-0.015, requires_grad=True), tensor(-0.0065, requires_grad=True), tensor(0.005, requires_grad=True), tensor(-0.041, requires_grad=True), tensor(-0.012, requires_grad=True), tensor(0.0035, requires_grad=True), tensor(-0.03, requires_grad=True), tensor(0.0065, requires_grad=True), tensor(-0.0215, requires_grad=True), tensor(0.015, requires_grad=True), tensor(0.029, requires_grad=True), tensor(0.008, requires_grad=True), tensor(-0.0125, requires_grad=True), tensor(-0.0485, requires_grad=True), tensor(0.026, requires_grad=True), tensor(-0.0045, requires_grad=True), tensor(-0.0035, requires_grad=True), tensor(-0.0105, requires_grad=True), tensor(0.0095, requires_grad=True)]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plotter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 72\u001b[0m\n\u001b[0;32m     70\u001b[0m results_experiment \u001b[38;5;241m=\u001b[39m [variance_experiment(shots) \u001b[38;5;28;01mfor\u001b[39;00m shots \u001b[38;5;129;01min\u001b[39;00m shot_vals]\n\u001b[0;32m     71\u001b[0m results_scaling \u001b[38;5;241m=\u001b[39m [variance_scaling(shots) \u001b[38;5;28;01mfor\u001b[39;00m shots \u001b[38;5;129;01min\u001b[39;00m shot_vals]\n\u001b[1;32m---> 72\u001b[0m plot \u001b[38;5;241m=\u001b[39m \u001b[43mplotter\u001b[49m(shot_vals, results_experiment, results_scaling)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plotter' is not defined"
     ]
    }
   ],
   "source": [
    "def variance_experiment(n_shots):\n",
    "    \"\"\"Run an experiment to determine the variance in an expectation\n",
    "    value computed with a given number of shots.\n",
    "\n",
    "    Args:\n",
    "        n_shots (int): The number of shots\n",
    "\n",
    "    Returns:\n",
    "        float: The variance in expectation value we obtain running the\n",
    "        circuit 100 times with n_shots shots each.\n",
    "    \"\"\"\n",
    "\n",
    "    # To obtain a variance, we run the circuit multiple times at each shot value.\n",
    "    n_trials = 100\n",
    "\n",
    "    ##################\n",
    "    # YOUR CODE HERE #\n",
    "\n",
    "    dev = qml.device('default.qubit', wires=1, shots=n_shots)\n",
    "    ##################\n",
    "\n",
    "    # CREATE A DEVICE WITH GIVEN NUMBER OF SHOTS\n",
    "\n",
    "    # DECORATE THE CIRCUIT BELOW TO CREATE A QNODE\n",
    "\n",
    "    @qml.qnode(dev)\n",
    "    def circuit():\n",
    "        qml.Hadamard(wires=0)\n",
    "        return qml.expval(qml.PauliZ(wires=0))\n",
    "\n",
    "    # RUN THE QNODE N_TRIALS TIMES AND RETURN THE VARIANCE OF THE RESULTS\n",
    "\n",
    "    variance = []\n",
    "    for i in range(n_trials):\n",
    "        variance.append(circuit())\n",
    "    print(variance)\n",
    "\n",
    "    return np.var(variance)\n",
    "\n",
    "\n",
    "def variance_scaling(n_shots):\n",
    "    \"\"\"Once you have determined how the variance in expectation value scales\n",
    "    with the number of shots, complete this function to programmatically\n",
    "    represent the relationship.\n",
    "\n",
    "    Args:\n",
    "        n_shots (int): The number of shots\n",
    "\n",
    "    Returns:\n",
    "        float: The variance in expectation value we expect to see when we run\n",
    "        an experiment with n_shots shots.\n",
    "    \"\"\"\n",
    "\n",
    "    # estimated_variance = 0\n",
    "\n",
    "    ##################\n",
    "    # YOUR CODE HERE #\n",
    "    ##################\n",
    "\n",
    "    # ESTIMATE THE VARIANCE BASED ON SHOT NUMBER\n",
    "\n",
    "    return 1/n_shots\n",
    "    # return estimated_variance\n",
    "\n",
    "\n",
    "# Various numbers of shots; you can change this\n",
    "shot_vals = [10, 20, 40, 100, 200, 400, 1000, 2000, 4000]\n",
    "\n",
    "# Used to plot your results\n",
    "results_experiment = [variance_experiment(shots) for shots in shot_vals]\n",
    "results_scaling = [variance_scaling(shots) for shots in shot_vals]\n",
    "plot = plotter(shot_vals, results_experiment, results_scaling)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
